## Behaviour

![](img/behaviour/neuroethology_workflow.png)

::: footer
Modern computational neuroethology workflow
:::

## Behaviour {auto-animate=true auto-animate-easing="ease-in-out"}

![](img/behaviour/neuroethology_workflow_annot.png)

::: footer
Modern computational neuroethology workflow
:::

## `movement` overview

![](img/behaviour/movement_overview.png)

::: footer
[movement.neuroinformatics.dev](https://movement.neuroinformatics.dev/)
:::

## `movement` example applications


## `movement` GUI
{{< video "img/behaviour/gui_tracks_demo.mp4" >}}


## `movement` future directions

:::{.incremental}
- Annotate space with regions of interest
- Annotate time with events of interest
- Align motion tracks with neurophysiological signals
- Bring more capabilities to the GUI
- More specialised metrics, useful for spatial navigation, social interactions, collective behaviour...
:::

::: footer
[Join the movement!](https://movement.neuroinformatics.dev/community/index.html)
:::

## `ethology`: mix-and-match computer vision tools

{{< video img/behaviour/sam2_demo_flipped.mp4 >}}

<!-- Mix and match computer vision tools, compare performance of equiv methods -->
<!-- - Use annotations as prompts for segmentation models, such as Segment Anything._ -->
<!-- - Programmatically curate manual annotations -->
<!-- - Use track-anything-models, compare trackers -->
<!-- _Support common video utilities: cropping frame size, compressing videos, clipping videos, identifying outlier frames..._ -->



